{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport warnings\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import r2_score\nfrom xgboost import XGBRegressor\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category = UserWarning)","metadata":{"execution":{"iopub.status.busy":"2025-01-22T18:57:04.962407Z","iopub.execute_input":"2025-01-22T18:57:04.962688Z","iopub.status.idle":"2025-01-22T18:57:07.925932Z","shell.execute_reply.started":"2025-01-22T18:57:04.962656Z","shell.execute_reply":"2025-01-22T18:57:07.924791Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"\n'''\nLoading the data\n'''\n\nfolder_path = \"/kaggle/input/store-sales-time-series-forecasting/\"\n\nholiday_event_df = pd.read_csv(os.path.join(folder_path,\"holidays_events.csv\"),\n                               dtype={'type': 'category',\n                                      'locale': 'category',\n                                      'locale_name': 'category',\n                                      'description': 'category',\n                                      'transferred': 'bool'},\n                               parse_dates=['date'],\n                               infer_datetime_format=True)\n\nholiday_event_df = holiday_event_df.set_index('date').to_period('D')\n\nholiday_event_df_duplicates = holiday_event_df[holiday_event_df.index.duplicated(keep=False)] #Find duplicate values in holidays\n\nholiday_event_df_without_duplicates = holiday_event_df[~holiday_event_df.index.duplicated(keep='first')] #Handle duplicate values in holidays\n\noil_df = pd.read_csv(os.path.join(folder_path,\"oil.csv\"),\n                     parse_dates=['date'],\n                     infer_datetime_format=True)\n\noil_df = oil_df.set_index('date').to_period('D')\n\noil_df = oil_df.interpolate() #Handle missing values in oil prices\n\noil_df.iloc[0] = oil_df.iloc[1] #Handle missing values in oil prices\n\noil_df.rename(columns={\"dcoilwtico\": \"oil_price\"}, inplace = True)\n\nstores_df = pd.read_csv(os.path.join(folder_path,\"stores.csv\"))\n\ntransaction_df = pd.read_csv(os.path.join(folder_path,\"transactions.csv\"),\n                             parse_dates=['date'],\n                             infer_datetime_format=True)\n\ntransaction_df['date'] = transaction_df['date'].dt.to_period('D')\ntransaction_df = transaction_df.set_index(['date', 'store_nbr']).sort_index()\n\ntrain_df = pd.read_csv(os.path.join(folder_path,\"train.csv\"),\n                                        usecols=['store_nbr', 'family', 'date','sales', 'onpromotion'],\n                                        dtype={'store_nbr': 'category',\n                                               'family': 'category',\n                                               'sales': 'float'},\n                                        parse_dates=['date'],\n                                        infer_datetime_format=True)\n\ntrain_df['date'] = train_df.date.dt.to_period('D')\ntrain_df = train_df.set_index('date').sort_index()\n\ncompetition_test_df = pd.read_csv(os.path.join(folder_path,\"test.csv\"),\n                                  usecols=['id','store_nbr', 'family', 'date', 'onpromotion'],\n                                  dtype={'store_nbr': 'category',\n                                         'family': 'category',\n                                         'onpromotion': 'uint32'},\n                                  parse_dates=['date'],\n                                  infer_datetime_format=True)\n\ncompetition_test_df['date'] = competition_test_df.date.dt.to_period('D')\ncompetition_test_df = competition_test_df.set_index('date').sort_index()","metadata":{"execution":{"iopub.status.busy":"2025-01-22T18:57:07.928505Z","iopub.execute_input":"2025-01-22T18:57:07.929733Z","iopub.status.idle":"2025-01-22T18:57:21.820416Z","shell.execute_reply.started":"2025-01-22T18:57:07.929681Z","shell.execute_reply":"2025-01-22T18:57:21.819159Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"'''\nBuilding a neural network to predict sales by store and family.\n'''\n\nX = train_df.loc['2016':'2017'].copy()\n\nX['day'] = X.index.day\nX['week'] = X.index.dayofweek\n\nX = X.join(oil_df, on='date')\nX['oil_price'] = X['oil_price'].interpolate()\n\nX['NewYear'] = (X.index.dayofyear == 1)\nX['holiday'] = X.index.to_series().isin(holiday_event_df.index)\n\nonehot_encoder = OneHotEncoder()\n\nencoded_week = onehot_encoder.fit_transform(X['week'].values.reshape(-1, 1))\n\nencoded_week_df = pd.DataFrame(encoded_week.toarray(), columns=onehot_encoder.get_feature_names_out(['week']), index=X.index)\n\nencoded_family = onehot_encoder.fit_transform(X['family'].values.reshape(-1, 1))\n\nencoded_family_df = pd.DataFrame(encoded_family.toarray(), columns=onehot_encoder.get_feature_names_out(['family']), index=X.index)\n\nencoded_store_nbr = onehot_encoder.fit_transform(X['store_nbr'].values.reshape(-1, 1))\n\nencoded_store_nbr_df = pd.DataFrame(encoded_store_nbr.toarray(), columns=onehot_encoder.get_feature_names_out(['store_nbr']), index=X.index)\n\nX = pd.concat([X, encoded_week_df, encoded_family_df, encoded_store_nbr_df], axis=1)\n\ny = X[['sales']].copy()\n\nX.drop(columns=['sales','week','family', 'store_nbr'], inplace = True)\n\nX[['NewYear','holiday']] = X[['NewYear','holiday']].astype(int)\n\ny_train, y_test = y[:\"2017-06-01\"], y[\"2017-06-02\":]\nX_train, X_test = X.loc[:\"2017-06-01\"], X.loc[\"2017-06-02\":]\n\nmodel = XGBRegressor(n_estimators = 1000,\n                     learning_rate = 0.01,\n                     max_depth = 5,\n                     objective = \"reg:squarederror\")\n\nmodel.fit(X_train,y_train)\n\ny_pred = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=['sales'])\n\nprint(\"\\nTest R2 of the xgboost model: {}\\n\".format(r2_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2025-01-22T18:57:21.821694Z","iopub.execute_input":"2025-01-22T18:57:21.822071Z","iopub.status.idle":"2025-01-22T18:58:40.046220Z","shell.execute_reply.started":"2025-01-22T18:57:21.822034Z","shell.execute_reply":"2025-01-22T18:58:40.044945Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nTest R2 of the xgboost model: 0.9112365454453908\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"'''\nPredicting sales for the competition dataset\n'''\n\nX_competition = competition_test_df.loc['2016':'2017'].copy()\n\nX_competition['day'] = X_competition.index.day\nX_competition['week'] = X_competition.index.dayofweek\n\nX_competition = X_competition.join(oil_df, on='date')\nX_competition['oil_price'] = X_competition['oil_price'].interpolate()\n\nX_competition['NewYear'] = (X_competition.index.dayofyear == 1)\nX_competition['holiday'] = X_competition.index.to_series().isin(holiday_event_df.index)\n\nonehot_encoder = OneHotEncoder()\n\nencoded_week = onehot_encoder.fit_transform(X_competition['week'].values.reshape(-1, 1))\n\nencoded_week_df = pd.DataFrame(encoded_week.toarray(), columns=onehot_encoder.get_feature_names_out(['week']), index=X_competition.index)\n\nencoded_family = onehot_encoder.fit_transform(X_competition['family'].values.reshape(-1, 1))\n\nencoded_family_df = pd.DataFrame(encoded_family.toarray(), columns=onehot_encoder.get_feature_names_out(['family']), index=X_competition.index)\n\nencoded_store_nbr = onehot_encoder.fit_transform(X_competition['store_nbr'].values.reshape(-1, 1))\n\nencoded_store_nbr_df = pd.DataFrame(encoded_store_nbr.toarray(), columns=onehot_encoder.get_feature_names_out(['store_nbr']), index=X_competition.index)\n\nX_competition = pd.concat([X_competition, encoded_week_df, encoded_family_df, encoded_store_nbr_df], axis=1)\n\nX_competition.drop(columns=['week','family', 'store_nbr'], inplace = True)\n\nX_competition[['NewYear','holiday']] = X_competition[['NewYear','holiday']].astype(int)\n\nX_competition = X_competition[X.columns]\n\ny_submit = competition_test_df[['id']].copy()\ny_submit['sales'] = model.predict(X_competition)\ny_submit.to_csv('submission.csv', index=False)\n\nprint(\"\\nBelow are the predictions for the competition data:\")\nprint(y_submit)","metadata":{"execution":{"iopub.status.busy":"2025-01-22T18:58:40.047387Z","iopub.execute_input":"2025-01-22T18:58:40.047680Z","iopub.status.idle":"2025-01-22T18:58:40.529894Z","shell.execute_reply.started":"2025-01-22T18:58:40.047653Z","shell.execute_reply":"2025-01-22T18:58:40.528596Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nBelow are the predictions for the competition data:\n                 id        sales\ndate                            \n2017-08-16  3000888    -6.228901\n2017-08-16  3000889    -6.228901\n2017-08-16  3000890    72.382362\n2017-08-16  3000891  2460.327881\n2017-08-16  3000892    -6.228901\n...             ...          ...\n2017-08-31  3029395   214.595459\n2017-08-31  3029396    22.865728\n2017-08-31  3029397  1408.985229\n2017-08-31  3029398   265.726593\n2017-08-31  3029399    22.865728\n\n[28512 rows x 2 columns]\n","output_type":"stream"}],"execution_count":4}]}