{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport warnings\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import r2_score\nfrom tensorflow.keras import layers, models, optimizers, regularizers\nfrom tensorflow.keras.losses import Huber\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category = UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T15:02:48.968345Z","iopub.execute_input":"2024-08-25T15:02:48.968756Z","iopub.status.idle":"2024-08-25T15:02:48.975707Z","shell.execute_reply.started":"2024-08-25T15:02:48.968719Z","shell.execute_reply":"2024-08-25T15:02:48.974536Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"'''\nLoading the data\n'''\n\nfolder_path = \"/kaggle/input/store-sales-time-series-forecasting/\"\n\nholiday_event_df = pd.read_csv(os.path.join(folder_path,\"holidays_events.csv\"),\n                               dtype={'type': 'category',\n                                      'locale': 'category',\n                                      'locale_name': 'category',\n                                      'description': 'category',\n                                      'transferred': 'bool'},\n                               parse_dates=['date'],\n                               infer_datetime_format=True)\n\nholiday_event_df = holiday_event_df.set_index('date').to_period('D')\n\nholiday_event_df_duplicates = holiday_event_df[holiday_event_df.index.duplicated(keep=False)] #Find duplicate values in holidays\n\nholiday_event_df_without_duplicates = holiday_event_df[~holiday_event_df.index.duplicated(keep='first')] #Handle duplicate values in holidays\n\noil_df = pd.read_csv(os.path.join(folder_path,\"oil.csv\"),\n                     parse_dates=['date'],\n                     infer_datetime_format=True)\n\noil_df = oil_df.set_index('date').to_period('D')\n\noil_df = oil_df.interpolate() #Handle missing values in oil prices\n\noil_df.iloc[0] = oil_df.iloc[1] #Handle missing values in oil prices\n\noil_df.rename(columns={\"dcoilwtico\": \"oil_price\"}, inplace = True)\n\nstores_df = pd.read_csv(os.path.join(folder_path,\"stores.csv\"))\n\ntransaction_df = pd.read_csv(os.path.join(folder_path,\"transactions.csv\"),\n                             parse_dates=['date'],\n                             infer_datetime_format=True)\n\ntransaction_df['date'] = transaction_df['date'].dt.to_period('D')\ntransaction_df = transaction_df.set_index(['date', 'store_nbr']).sort_index()\n\ntrain_df = pd.read_csv(os.path.join(folder_path,\"train.csv\"),\n                                        usecols=['store_nbr', 'family', 'date','sales', 'onpromotion'],\n                                        dtype={'store_nbr': 'category',\n                                               'family': 'category',\n                                               'sales': 'float'},\n                                        parse_dates=['date'],\n                                        infer_datetime_format=True)\n\ntrain_df['date'] = train_df.date.dt.to_period('D')\ntrain_df = train_df.set_index('date').sort_index()\n\ncompetition_test_df = pd.read_csv(os.path.join(folder_path,\"test.csv\"),\n                                  usecols=['id','store_nbr', 'family', 'date', 'onpromotion'],\n                                  dtype={'store_nbr': 'category',\n                                         'family': 'category',\n                                         'onpromotion': 'uint32'},\n                                  parse_dates=['date'],\n                                  infer_datetime_format=True)\n\ncompetition_test_df['date'] = competition_test_df.date.dt.to_period('D')\ncompetition_test_df = competition_test_df.set_index('date').sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:02:48.997662Z","iopub.execute_input":"2024-08-25T15:02:48.998047Z","iopub.status.idle":"2024-08-25T15:03:03.350028Z","shell.execute_reply.started":"2024-08-25T15:02:48.998011Z","shell.execute_reply":"2024-08-25T15:03:03.348895Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"'''\nBuilding a neural network to predict sales by store and family.\n'''\n\nX = train_df.loc['2016':'2017'].copy()\n\nX['day'] = X.index.day\nX['week'] = X.index.dayofweek\n\nX = X.join(oil_df, on='date')\nX['oil_price'] = X['oil_price'].interpolate()\n\nX['NewYear'] = (X.index.dayofyear == 1)\nX['holiday'] = X.index.to_series().isin(holiday_event_df.index)\n\nonehot_encoder = OneHotEncoder()\n\nencoded_week = onehot_encoder.fit_transform(X['week'].values.reshape(-1, 1))\n\nencoded_week_df = pd.DataFrame(encoded_week.toarray(), columns=onehot_encoder.get_feature_names_out(['week']), index=X.index)\n\nencoded_family = onehot_encoder.fit_transform(X['family'].values.reshape(-1, 1))\n\nencoded_family_df = pd.DataFrame(encoded_family.toarray(), columns=onehot_encoder.get_feature_names_out(['family']), index=X.index)\n\nencoded_store_nbr = onehot_encoder.fit_transform(X['store_nbr'].values.reshape(-1, 1))\n\nencoded_store_nbr_df = pd.DataFrame(encoded_store_nbr.toarray(), columns=onehot_encoder.get_feature_names_out(['store_nbr']), index=X.index)\n\ncolumns_to_be_scaled = ['onpromotion', 'oil_price', 'day']\n\nscaler = StandardScaler()\n\nscaled_data = scaler.fit_transform(X.loc[:,columns_to_be_scaled])\n\nscaled_data_df = pd.DataFrame(scaled_data, columns=[i + \"_scaled\" for i in columns_to_be_scaled], index=X.index)\n\nX = pd.concat([X, scaled_data_df, encoded_week_df, encoded_family_df, encoded_store_nbr_df], axis=1)\n\ny = X[['sales']].copy()\n\nX.drop(columns=columns_to_be_scaled + ['sales','week','family', 'store_nbr'], inplace = True)\n\nX[['NewYear','holiday']] = X[['NewYear','holiday']].astype(int)\n\ny_train, y_test = y[:\"2017-06-01\"], y[\"2017-06-02\":]\nX_train, X_test = X.loc[:\"2017-06-01\"], X.loc[\"2017-06-02\":]\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(32, activation='relu'))\n\nmodel.add(layers.Dense(1, activation='linear'))\n\noptimizer = optimizers.Adam(learning_rate=0.001)\n\nhuber_loss = Huber(delta=1.0)\n\nmodel.compile(optimizer=optimizer, loss=huber_loss, metrics=['mae'])\n\nmodel_params = {'epochs' : 20, 'batch_size' : 64, 'validation_split' : 0.1}\n\nmodel.fit(X_train,y_train, **model_params)\n\ny_pred = pd.DataFrame(model.predict(X_test).flatten(), index=X_test.index, columns=['sales'])\n\nprint(\"\\nTest R2 of the neural network model: {}\\n\".format(r2_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:03:03.352060Z","iopub.execute_input":"2024-08-25T15:03:03.352433Z","iopub.status.idle":"2024-08-25T15:26:47.865948Z","shell.execute_reply.started":"2024-08-25T15:03:03.352397Z","shell.execute_reply":"2024-08-25T15:26:47.864780Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 5ms/step - loss: 201.3544 - mae: 201.0418 - val_loss: 102.8614 - val_mae: 101.8168\nEpoch 2/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 116.3866 - mae: 115.1463 - val_loss: 101.9088 - val_mae: 100.1712\nEpoch 3/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 107.9613 - mae: 106.0967 - val_loss: 96.2569 - val_mae: 94.0395\nEpoch 4/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - loss: 103.5793 - mae: 101.2681 - val_loss: 96.9831 - val_mae: 94.4362\nEpoch 5/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 101.4191 - mae: 98.7994 - val_loss: 91.8568 - val_mae: 89.0529\nEpoch 6/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 99.9038 - mae: 97.0650 - val_loss: 99.1922 - val_mae: 96.2215\nEpoch 7/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 97.6180 - mae: 94.6108 - val_loss: 94.9627 - val_mae: 91.8761\nEpoch 8/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 95.9368 - mae: 92.8207 - val_loss: 94.9469 - val_mae: 91.7433\nEpoch 9/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 95.8271 - mae: 92.6031 - val_loss: 89.4049 - val_mae: 86.1294\nEpoch 10/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 95.1583 - mae: 91.8745 - val_loss: 102.0497 - val_mae: 98.7185\nEpoch 11/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 94.1569 - mae: 90.8075 - val_loss: 98.3765 - val_mae: 94.9932\nEpoch 12/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 93.2082 - mae: 89.8053 - val_loss: 99.4048 - val_mae: 95.9770\nEpoch 13/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 92.4086 - mae: 88.9752 - val_loss: 99.6338 - val_mae: 96.1620\nEpoch 14/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 92.1324 - mae: 88.6505 - val_loss: 98.6149 - val_mae: 95.0928\nEpoch 15/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 91.8334 - mae: 88.3040 - val_loss: 94.2082 - val_mae: 90.6608\nEpoch 16/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 91.1448 - mae: 87.5943 - val_loss: 90.3521 - val_mae: 86.7712\nEpoch 17/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 90.6257 - mae: 87.0416 - val_loss: 92.6079 - val_mae: 89.0031\nEpoch 18/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 90.6359 - mae: 87.0394 - val_loss: 93.1392 - val_mae: 89.5488\nEpoch 19/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - loss: 89.8343 - mae: 86.2465 - val_loss: 100.8583 - val_mae: 97.2664\nEpoch 20/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 89.3592 - mae: 85.7665 - val_loss: 94.6312 - val_mae: 91.0163\n\u001b[1m4177/4177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n\nTest R2 of the neural network model: 0.9097983609669353\n\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nPredicting sales for the competition dataset\n'''\n\nX_competition = competition_test_df.loc['2016':'2017'].copy()\n\nX_competition['day'] = X_competition.index.day\nX_competition['week'] = X_competition.index.dayofweek\n\nX_competition = X_competition.join(oil_df, on='date')\nX_competition['oil_price'] = X_competition['oil_price'].interpolate()\n\nX_competition['NewYear'] = (X_competition.index.dayofyear == 1)\nX_competition['holiday'] = X_competition.index.to_series().isin(holiday_event_df.index)\n\nonehot_encoder = OneHotEncoder()\n\nencoded_week = onehot_encoder.fit_transform(X_competition['week'].values.reshape(-1, 1))\n\nencoded_week_df = pd.DataFrame(encoded_week.toarray(), columns=onehot_encoder.get_feature_names_out(['week']), index=X_competition.index)\n\nencoded_family = onehot_encoder.fit_transform(X_competition['family'].values.reshape(-1, 1))\n\nencoded_family_df = pd.DataFrame(encoded_family.toarray(), columns=onehot_encoder.get_feature_names_out(['family']), index=X_competition.index)\n\nencoded_store_nbr = onehot_encoder.fit_transform(X_competition['store_nbr'].values.reshape(-1, 1))\n\nencoded_store_nbr_df = pd.DataFrame(encoded_store_nbr.toarray(), columns=onehot_encoder.get_feature_names_out(['store_nbr']), index=X_competition.index)\n\ncolumns_to_be_scaled = ['onpromotion', 'oil_price', 'day']\n\nscaler = StandardScaler()\n\nscaled_data = scaler.fit_transform(X_competition.loc[:,columns_to_be_scaled])\n\nscaled_data_df = pd.DataFrame(scaled_data, columns=[i + \"_scaled\" for i in columns_to_be_scaled], index=X_competition.index)\n\nX_competition = pd.concat([X_competition, scaled_data_df, encoded_week_df, encoded_family_df, encoded_store_nbr_df], axis=1)\n\nX_competition.drop(columns=columns_to_be_scaled + ['week','family', 'store_nbr'], inplace = True)\n\nX_competition[['NewYear','holiday']] = X_competition[['NewYear','holiday']].astype(int)\n\nX_competition = X_competition[X.columns]\n\ny_submit = competition_test_df[['id']].copy()\ny_submit['sales'] = model.predict(X_competition).flatten()\ny_submit.to_csv('submission.csv', index=False)\n\nprint(\"\\nBelow are the predictions for the competition data:\")\nprint(y_submit)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T15:26:47.867461Z","iopub.execute_input":"2024-08-25T15:26:47.867804Z","iopub.status.idle":"2024-08-25T15:26:49.661485Z","shell.execute_reply.started":"2024-08-25T15:26:47.867768Z","shell.execute_reply":"2024-08-25T15:26:49.660432Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n\nBelow are the predictions for the competition data:\n                 id        sales\ndate                            \n2017-08-16  3000888     1.697447\n2017-08-16  3000889     0.551759\n2017-08-16  3000890     2.987623\n2017-08-16  3000891  2421.897949\n2017-08-16  3000892     0.693404\n...             ...          ...\n2017-08-31  3029395   344.515564\n2017-08-31  3029396    85.243202\n2017-08-31  3029397  1099.382568\n2017-08-31  3029398     0.940957\n2017-08-31  3029399     6.397253\n\n[28512 rows x 2 columns]\n","output_type":"stream"}]}]}