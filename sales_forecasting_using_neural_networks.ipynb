{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":29781,"databundleVersionId":2887556,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport warnings\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import r2_score\nfrom tensorflow.keras import layers, models, optimizers, regularizers\nfrom tensorflow.keras.losses import Huber\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category = UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-01-22T22:02:52.978061Z","iopub.execute_input":"2025-01-22T22:02:52.978551Z","iopub.status.idle":"2025-01-22T22:03:10.577119Z","shell.execute_reply.started":"2025-01-22T22:02:52.978504Z","shell.execute_reply":"2025-01-22T22:03:10.575953Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"'''\nLoading the data\n'''\n\nfolder_path = \"/kaggle/input/store-sales-time-series-forecasting/\"\n\nholiday_event_df = pd.read_csv(os.path.join(folder_path,\"holidays_events.csv\"),\n                               dtype={'type': 'category',\n                                      'locale': 'category',\n                                      'locale_name': 'category',\n                                      'description': 'category',\n                                      'transferred': 'bool'},\n                               parse_dates=['date'],\n                               infer_datetime_format=True)\n\nholiday_event_df = holiday_event_df.set_index('date').to_period('D')\n\nholiday_event_df_duplicates = holiday_event_df[holiday_event_df.index.duplicated(keep=False)] #Find duplicate values in holidays\n\nholiday_event_df_without_duplicates = holiday_event_df[~holiday_event_df.index.duplicated(keep='first')] #Handle duplicate values in holidays\n\noil_df = pd.read_csv(os.path.join(folder_path,\"oil.csv\"),\n                     parse_dates=['date'],\n                     infer_datetime_format=True)\n\noil_df = oil_df.set_index('date').to_period('D')\n\noil_df = oil_df.interpolate() #Handle missing values in oil prices\n\noil_df.iloc[0] = oil_df.iloc[1] #Handle missing values in oil prices\n\noil_df.rename(columns={\"dcoilwtico\": \"oil_price\"}, inplace = True)\n\nstores_df = pd.read_csv(os.path.join(folder_path,\"stores.csv\"))\n\ntransaction_df = pd.read_csv(os.path.join(folder_path,\"transactions.csv\"),\n                             parse_dates=['date'],\n                             infer_datetime_format=True)\n\ntransaction_df['date'] = transaction_df['date'].dt.to_period('D')\ntransaction_df = transaction_df.set_index(['date', 'store_nbr']).sort_index()\n\ntrain_df = pd.read_csv(os.path.join(folder_path,\"train.csv\"),\n                                        usecols=['store_nbr', 'family', 'date','sales', 'onpromotion'],\n                                        dtype={'store_nbr': 'category',\n                                               'family': 'category',\n                                               'sales': 'float'},\n                                        parse_dates=['date'],\n                                        infer_datetime_format=True)\n\ntrain_df['date'] = train_df.date.dt.to_period('D')\ntrain_df = train_df.set_index('date').sort_index()\n\ncompetition_test_df = pd.read_csv(os.path.join(folder_path,\"test.csv\"),\n                                  usecols=['id','store_nbr', 'family', 'date', 'onpromotion'],\n                                  dtype={'store_nbr': 'category',\n                                         'family': 'category',\n                                         'onpromotion': 'uint32'},\n                                  parse_dates=['date'],\n                                  infer_datetime_format=True)\n\ncompetition_test_df['date'] = competition_test_df.date.dt.to_period('D')\ncompetition_test_df = competition_test_df.set_index('date').sort_index()","metadata":{"execution":{"iopub.status.busy":"2025-01-22T22:03:10.579346Z","iopub.execute_input":"2025-01-22T22:03:10.579969Z","iopub.status.idle":"2025-01-22T22:03:25.014153Z","shell.execute_reply.started":"2025-01-22T22:03:10.579931Z","shell.execute_reply":"2025-01-22T22:03:25.012972Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"'''\nBuilding a neural network to predict sales by store and family.\n'''\n\nX = train_df.loc['2016':'2017'].copy()\n\nX['day'] = X.index.day\nX['week'] = X.index.dayofweek\n\nX = X.join(oil_df, on='date')\nX['oil_price'] = X['oil_price'].interpolate()\n\nX['NewYear'] = (X.index.dayofyear == 1)\nX['holiday'] = X.index.to_series().isin(holiday_event_df.index)\n\ny = X[['sales']].copy()\n\nX_competition = competition_test_df.loc['2016':'2017'].copy()\n\nX_competition['day'] = X_competition.index.day\nX_competition['week'] = X_competition.index.dayofweek\n\nX_competition = X_competition.join(oil_df, on='date')\nX_competition['oil_price'] = X_competition['oil_price'].interpolate()\n\nX_competition['NewYear'] = (X_competition.index.dayofyear == 1)\nX_competition['holiday'] = X_competition.index.to_series().isin(holiday_event_df.index)\n\ny_train, y_test = y[:\"2017-06-01\"], y[\"2017-06-02\":]\nX_train, X_test = X.loc[:\"2017-06-01\"], X.loc[\"2017-06-02\":]\n\nscaler = StandardScaler()\n\ncolumns_to_be_scaled = ['onpromotion', 'oil_price', 'day']\n\nscaled_train_data = scaler.fit_transform(X_train.loc[:,columns_to_be_scaled])\n\nscaled_train_data_df = pd.DataFrame(scaled_train_data, columns=[i + \"_scaled\" for i in columns_to_be_scaled], index=X_train.index)\n\nX_train = pd.concat([X_train, scaled_train_data_df], axis=1)\n\nscaled_test_data = scaler.transform(X_test.loc[:,columns_to_be_scaled])\n\nscaled_test_data_df = pd.DataFrame(scaled_test_data, columns=[i + \"_scaled\" for i in columns_to_be_scaled], index=X_test.index)\n\nX_test = pd.concat([X_test, scaled_test_data_df], axis=1)\n\nscaled_competition_data = scaler.transform(X_competition.loc[:,columns_to_be_scaled])\n\nscaled_competition_data_df = pd.DataFrame(scaled_competition_data, columns=[i + \"_scaled\" for i in columns_to_be_scaled], index=X_competition.index)\n\nX_competition = pd.concat([X_competition, scaled_competition_data_df], axis=1)\n\ncolumns_to_be_encoded = ['week', 'family', 'store_nbr']\n\nfor column in columns_to_be_encoded:\n    \n    onehot_encoder = OneHotEncoder()\n    \n    encoded_train_column = onehot_encoder.fit_transform(X_train[column].values.reshape(-1, 1))\n\n    encoded_train_column_df = pd.DataFrame(encoded_train_column.toarray(), columns=onehot_encoder.get_feature_names_out([column]), index=X_train.index)\n    \n    X_train = pd.concat([X_train, encoded_train_column_df], axis=1)\n    \n    encoded_test_column = onehot_encoder.transform(X_test[column].values.reshape(-1, 1))\n\n    encoded_test_column_df = pd.DataFrame(encoded_test_column.toarray(), columns=onehot_encoder.get_feature_names_out([column]), index=X_test.index)\n    \n    X_test = pd.concat([X_test, encoded_test_column_df], axis=1)\n    \n    encoded_competition_column = onehot_encoder.transform(X_competition[column].values.reshape(-1, 1))\n\n    encoded_competition_column_df = pd.DataFrame(encoded_competition_column.toarray(), columns=onehot_encoder.get_feature_names_out([column]), index=X_competition.index)\n    \n    X_competition = pd.concat([X_competition, encoded_competition_column_df], axis=1)\n\nX_train.drop(columns=columns_to_be_scaled + ['sales'] + columns_to_be_encoded, inplace = True)\n\nX_train[['NewYear','holiday']] = X_train[['NewYear','holiday']].astype(int)\n\nX_test.drop(columns=columns_to_be_scaled + ['sales'] + columns_to_be_encoded, inplace = True)\n\nX_test[['NewYear','holiday']] = X_test[['NewYear','holiday']].astype(int)\n\nX_competition.drop(columns=columns_to_be_scaled + columns_to_be_encoded, inplace = True)\n\nX_competition[['NewYear','holiday']] = X_competition[['NewYear','holiday']].astype(int)\n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.3))\n\nmodel.add(layers.Dense(32, activation='relu'))\n\nmodel.add(layers.Dense(1, activation='linear'))\n\noptimizer = optimizers.Adam(learning_rate=0.001)\n\nhuber_loss = Huber(delta=1.0)\n\nmodel.compile(optimizer=optimizer, loss=huber_loss, metrics=['mae'])\n\nmodel_params = {'epochs' : 20, 'batch_size' : 64, 'validation_split' : 0.1}\n\nmodel.fit(X_train,y_train, **model_params)\n\ny_pred = pd.DataFrame(model.predict(X_test).flatten(), index=X_test.index, columns=['sales'])\n\nprint(\"\\nTest R2 of the neural network model: {}\\n\".format(r2_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2025-01-22T22:03:25.016247Z","iopub.execute_input":"2025-01-22T22:03:25.016705Z","iopub.status.idle":"2025-01-22T22:29:38.203841Z","shell.execute_reply.started":"2025-01-22T22:03:25.016657Z","shell.execute_reply":"2025-01-22T22:29:38.202351Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - loss: 201.4458 - mae: 201.1383 - val_loss: 106.3776 - val_mae: 105.3495\nEpoch 2/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - loss: 115.8918 - mae: 114.6557 - val_loss: 98.9592 - val_mae: 97.1898\nEpoch 3/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - loss: 108.6243 - mae: 106.7017 - val_loss: 102.3998 - val_mae: 100.1070\nEpoch 4/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 102.9283 - mae: 100.5422 - val_loss: 95.0710 - val_mae: 92.4249\nEpoch 5/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 100.4157 - mae: 97.7003 - val_loss: 96.9193 - val_mae: 94.0115\nEpoch 6/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 98.3644 - mae: 95.4100 - val_loss: 93.8389 - val_mae: 90.7272\nEpoch 7/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 97.3543 - mae: 94.2191 - val_loss: 94.8243 - val_mae: 91.5831\nEpoch 8/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - loss: 96.7299 - mae: 93.4733 - val_loss: 93.5782 - val_mae: 90.2600\nEpoch 9/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 94.9544 - mae: 91.6233 - val_loss: 96.4230 - val_mae: 93.0059\nEpoch 10/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6ms/step - loss: 94.7913 - mae: 91.3724 - val_loss: 103.8636 - val_mae: 100.4055\nEpoch 11/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 93.1238 - mae: 89.6599 - val_loss: 91.6150 - val_mae: 88.1178\nEpoch 12/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 92.8551 - mae: 89.3444 - val_loss: 93.7537 - val_mae: 90.2169\nEpoch 13/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 91.6462 - mae: 88.1162 - val_loss: 94.4633 - val_mae: 90.8963\nEpoch 14/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 91.9192 - mae: 88.3492 - val_loss: 95.0404 - val_mae: 91.4457\nEpoch 15/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 91.0820 - mae: 87.4818 - val_loss: 97.8336 - val_mae: 94.1856\nEpoch 16/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 91.0013 - mae: 87.3471 - val_loss: 101.4084 - val_mae: 97.7370\nEpoch 17/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 89.5459 - mae: 85.8665 - val_loss: 97.5281 - val_mae: 93.8193\nEpoch 18/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 90.4094 - mae: 86.7068 - val_loss: 94.6644 - val_mae: 90.9257\nEpoch 19/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - loss: 88.7488 - mae: 85.0196 - val_loss: 95.3704 - val_mae: 91.6127\nEpoch 20/20\n\u001b[1m12956/12956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - loss: 89.5238 - mae: 85.7631 - val_loss: 96.2868 - val_mae: 92.5185\n\u001b[1m4177/4177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n\nTest R2 of the neural network model: 0.8961898854428372\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"'''\nPredicting sales for the competition dataset\n'''\nX_competition = X_competition[X_train.columns]\n\ny_submit = competition_test_df[['id']].copy()\ny_submit['sales'] = model.predict(X_competition).flatten()\ny_submit.to_csv('submission.csv', index=False)\n\nprint(\"\\nBelow are the predictions for the competition data:\")\nprint(y_submit)","metadata":{"execution":{"iopub.status.busy":"2025-01-22T22:29:38.205502Z","iopub.execute_input":"2025-01-22T22:29:38.206144Z","iopub.status.idle":"2025-01-22T22:29:40.808665Z","shell.execute_reply.started":"2025-01-22T22:29:38.206087Z","shell.execute_reply":"2025-01-22T22:29:40.807304Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n\nBelow are the predictions for the competition data:\n                 id        sales\ndate                            \n2017-08-16  3000888     4.243020\n2017-08-16  3000889     0.675208\n2017-08-16  3000890     4.340920\n2017-08-16  3000891  2206.938232\n2017-08-16  3000892     0.844535\n...             ...          ...\n2017-08-31  3029395   305.319824\n2017-08-31  3029396    71.075508\n2017-08-31  3029397  1066.058838\n2017-08-31  3029398     2.239564\n2017-08-31  3029399     7.420100\n\n[28512 rows x 2 columns]\n","output_type":"stream"}],"execution_count":4}]}